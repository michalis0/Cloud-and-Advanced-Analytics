{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install gradio vertexai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vertexai\n",
    "from vertexai.preview.generative_models import GenerativeModel, ChatSession\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hello world with Gemini API\n",
    "Answers are generated based on a question to Gemini.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'path/to/your/credentials.json'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of Argentina is Buenos Aires.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GenerativeModel(\"gemini-2.0-flash-001\")\n",
    "\n",
    "question = 'What is the capital of Argentina?'\n",
    "response = model.generate_content(question)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat conversations with Gemini\n",
    "Gemini enables us to have a conversation. The ChatSession class simplifies the process by managing the state of the conversation, so unlike with generate_content, you do not have to store the conversation history as a list. With start_chat the history of the whole conversation is saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[role: \"user\"\n",
       " parts {\n",
       "   text: \"What is the capital of Chile?\"\n",
       " },\n",
       " role: \"model\"\n",
       " parts {\n",
       "   text: \"The capital of Chile is Santiago. It is located in the central region of the country, in the Santiago Metropolitan Region. Santiago is the largest city in Chile, with a population of over 6 million people. The city is a major economic and cultural center for Chile, and it is home to many important historical and cultural landmarks. The city was founded in 1541 by Pedro de Valdivia, a Spanish conquistador. In 1810, Chile declared independence from Spain, and Santiago became the capital of the new Chilean Republic. Today, Santiago is a modern and cosmopolitan city that is home to a diverse population. The city is a popular tourist destination, and it is known for its beautiful architecture, its vibrant nightlife, and its many delicious restaurants.\"\n",
       " },\n",
       " role: \"user\"\n",
       " parts {\n",
       "   text: \"What is the capital of Bolivia?\"\n",
       " },\n",
       " role: \"model\"\n",
       " parts {\n",
       "   text: \"The capital of Bolivia is Sucre. It is located in the south-central part of the country, in the Chuquisaca Department. Sucre is the constitutional capital of Bolivia, and it is the seat of the Bolivian Supreme Court and other important government institutions. The city is also a major cultural center for Bolivia, and it is home to many important historical and cultural landmarks. Sucre was founded in 1538 by Pedro de Anzures, a Spanish conquistador. The city was named after Pedro de la Gasca, a Spanish official who helped to suppress a rebellion against the Spanish Crown. Sucre served as the capital of the Spanish colony of Upper Peru until 1825, when Bolivia declared independence. Sucre remained the capital of Bolivia until 1898, when La Paz was designated as the administrative capital. Today, Sucre is a charming and historic city that is well worth a visit.\"\n",
       " }]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat = model.start_chat(history=[])\n",
    "countries = ['Chile', 'Bolivia']\n",
    "\n",
    "for country in countries:\n",
    "    message = f'What is the capital of {country}?'\n",
    "    chat.send_message(message)\n",
    "\n",
    "print(chat.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also ask questions about the history of the conversation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You asked me two questions about capital cities. \\r\\n\\r\\nThe first question was: What is the capital of Chile?\\r\\n\\r\\nThe second question was: What is the capital of Bolivia?'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chat.send_message('From which countries did I ask you the capital city?')\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming Gradio Chatbots\n",
    "Gradio is the quickest way to showcase your machine learning model through a user-friendly web interface, making it accessible to everyone, everywhere!\n",
    "\n",
    "To develop chatbots, there are many ways to make a conversation in Gradio. In this tutorial, we will use gr.ChatInterface()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yassineabdennadher/miniconda3/envs/myenv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import gradio as gr\n",
    "\n",
    "def slow_echo(message, history):\n",
    "    for i in range(len(message)):\n",
    "        time.sleep(0.3)\n",
    "        yield \"You typed: \" + message[: i+1]\n",
    "\n",
    "gr.ChatInterface(slow_echo).launch(share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With that code, the system response is the same as the input text in the interface."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will merge the Gemini and Gradio code to make a chatbot that responds to the input text. The code is edited to make the undo and clear buttons of the interface work.\n",
    "\n",
    "**Note**: You should stop the cell just above to be able to run this one !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interruption in main thread... closing server.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import gradio as gr\n",
    "from vertexai.generative_models import Content, Part  # Import Part class as well\n",
    "\n",
    "chat = model.start_chat(history=[])\n",
    "\n",
    "def transform_history(history):\n",
    "    new_history = []\n",
    "    for user_input, model_response in history:\n",
    "        new_history.append(Content(parts=[Part.from_text(user_input)], role=\"user\"))\n",
    "        new_history.append(Content(parts=[Part.from_text(model_response)], role=\"model\"))\n",
    "    return new_history\n",
    "\n",
    "def response(message, history):\n",
    "    global chat\n",
    "    # The history will be the same as in Gradio, the 'Undo' and 'Clear' buttons will work correctly.\n",
    "    chat = model.start_chat(history=transform_history(history))\n",
    "    response = chat.send_message(message)\n",
    "\n",
    "    # Each character of the answer is displayed\n",
    "    for i in range(len(response.text)):\n",
    "        time.sleep(0.05)\n",
    "        yield response.text[: i+1]\n",
    "\n",
    "gr.ChatInterface(response,\n",
    "                 title='Gemini Chat',\n",
    "                 textbox=gr.Textbox(placeholder=\"Question to Gemini\")).launch(debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chatbot pizza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interruption in main thread... closing server.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import gradio as gr\n",
    "from vertexai.generative_models import Content, Part\n",
    "\n",
    "# PizzaBot context message\n",
    "system_message = \"\"\"\n",
    "You are PizzaBot, an automated service to collect orders for a pizza restaurant. \\\n",
    "You first greet the customer, then collect the order, \\\n",
    "and then ask if it's a pickup or delivery. \\\n",
    "You wait to collect the entire order, then summarize it and check for a final \\\n",
    "time if the customer wants to add anything else. \\\n",
    "If it's a delivery, you ask for an address. \\\n",
    "Finally you collect the payment. \\\n",
    "Make sure to clarify all options, extras, and sizes to uniquely \\\n",
    "identify the item from the menu. \\\n",
    "You respond in a short, very conversational friendly style. \\\n",
    "The menu includes \\\n",
    "pepperoni pizza  12.95, 10.00, 7.00 \\\n",
    "cheese pizza   10.95, 9.25, 6.50 \\\n",
    "eggplant pizza   11.95, 9.75, 6.75 \\\n",
    "fries 4.50, 3.50 \\\n",
    "greek salad 7.25 \\\n",
    "Toppings: \\\n",
    "extra cheese 2.00, \\\n",
    "mushrooms 1.50 \\\n",
    "sausage 3.00 \\\n",
    "canadian bacon 3.50 \\\n",
    "AI sauce 1.50 \\\n",
    "peppers 1.00 \\\n",
    "Drinks: \\\n",
    "coke 3.00, 2.00, 1.00 \\\n",
    "sprite 3.00, 2.00, 1.00 \\\n",
    "bottled water 5.00 \\\n",
    "\"\"\"\n",
    "\n",
    "# Initialize chat\n",
    "chat = model.start_chat(history=[])\n",
    "\n",
    "# Send the initial system message and get the initial response from the model\n",
    "initial_message = Content(parts=[Part.from_text(system_message)], role=\"user\")\n",
    "initial_response = chat.send_message(system_message)\n",
    "\n",
    "# Prepare the initial history\n",
    "chat_history = [\n",
    "    (system_message, initial_response.text)\n",
    "]\n",
    "\n",
    "def transform_history(history):\n",
    "    new_history = []\n",
    "    for user_input, model_response in history:\n",
    "        new_history.append(Content(parts=[Part.from_text(user_input)], role=\"user\"))\n",
    "        new_history.append(Content(parts=[Part.from_text(model_response)], role=\"model\"))\n",
    "    return new_history\n",
    "\n",
    "def response(message, history):\n",
    "    global chat_history\n",
    "    # Transform the history to include the initial system message and response\n",
    "    transformed_history = transform_history(chat_history + history)\n",
    "    \n",
    "    # Initialize the chat with the current chat history\n",
    "    chat = model.start_chat(history=transformed_history)\n",
    "    \n",
    "    # Send the user's message and get the response from the model\n",
    "    model_response = chat.send_message(message)\n",
    "    \n",
    "    # Each character of the answer is displayed\n",
    "    for i in range(len(model_response.text)):\n",
    "        time.sleep(0.05)\n",
    "        yield model_response.text[: i + 1]\n",
    "    \n",
    "    # Update the chat history with the latest user and model messages\n",
    "    chat_history.append((message, model_response.text))\n",
    "\n",
    "gr.ChatInterface(response,\n",
    "                 title='PizzaBot Chat',\n",
    "                 textbox=gr.Textbox(placeholder=\"Place your pizza order\")).launch(debug=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXERCISE :\n",
    "\n",
    "This a list of 5 IKEA tables with description, material, dimension.\n",
    "\n",
    "Create a chatbot that accepts preferences of users that wish to buy a table and chooses one for them.\n",
    "\n",
    "\n",
    "LISABO, Ash veneer, 140x78 cm\n",
    "MÖRBYLÅNGA\n",
    "Table, 220x100 cm\n",
    "EKEDALEN\n",
    "Extendable table, 180/240x90 cm\n",
    "GUNNEBY\n",
    "Table, 200x80 cm\n",
    "DANDERYD\n",
    "Dining table, 130x80 cm\n",
    "TARSELE\n",
    "Extendable table, 150/200x80 cm\n",
    "\n",
    "\n",
    "\n",
    "What happens if you insult the chatbot?\n",
    "What if you go off-topic?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
