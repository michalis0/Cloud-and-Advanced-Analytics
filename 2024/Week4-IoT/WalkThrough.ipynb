{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/michalis0/Cloud-and-Advanced-Analytics/blob/main/2024/Week4-IoT/WalkThrough.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GD8PtRXo_l1H"
      },
      "source": [
        "# Creating a simple indoor/outdoor weather monitoring system\n",
        "\n",
        "### Learning goals\n",
        "By the end of this lab you will learn:\n",
        "- How to setup an M5stack core2 device and connect it to Internet.\n",
        "- How to program an M5stack device using the uiFlow platform (https://flow.m5stack.com/).\n",
        "- How to insert new data into a bigQuery database.\n",
        "- How to get current weather data for a specific location using the openweather api (https://home.openweathermap.org/).\n",
        "- Creating a webapp with different endpoints using Flask and deploying it using GCloud cloud run."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIZC4850_l1I"
      },
      "source": [
        "-------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MldJ52su_l1I"
      },
      "source": [
        "# 1. **Introduction and IOT devices:**\n",
        "Welcome to the Cloud and Advanced Analytics lab 4. In this lab, you will get know about M5stck IoT devices and sensors. You will program an M5stack device with an ENV-III sensor to build a simple weather station. Then you will push the weather data from the M5stack device to a BigQuery database in order to keep track of the historical weather data.\n",
        "\n",
        "\n",
        "### IoT devices\n",
        "In this lab you will work with the [M5stack Core2](https://docs.m5stack.com/en/core/core2) device and the [ENV-III unit](https://docs.m5stack.com/en/unit/envIII) which measures the temperature, humidity, etc.\n",
        "\n",
        "\n",
        "<!-- <img src=\"./imgs/core2_01.webp\" width=\"200\"> <img src=\"./imgs/envIII_01.webp\" width=\"200\">  -->\n",
        "\n",
        "<div class=\"row\">\n",
        "            <img src=\"https://drive.usercontent.google.com/download?id=110inQJbybfC9nBbJQj65fV0rPjKZ9tIk\" width=\"300\">\n",
        "            <img src=\"https://drive.usercontent.google.com/download?id=19a_ROkvIBvTpgARpRr7b901_dKWLW7kH\" width=\"300\">\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NCkqWGS_l1J"
      },
      "source": [
        "-------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qT9oQQoo_l1J"
      },
      "source": [
        "# **2. Setting up the weather sensor for measuring the indoor temperature and humidity**\n",
        "\n",
        "In this part, following the instructions mentioned in the lecture, we will follow the following steps:\n",
        "1. Connect the Core2 device to the power and connect it to the \"iot-unil\" WiFi network.\n",
        "2. Connect the ENV-III sensor to the Core2 device.\n",
        "3. Go to https://flow.m5stack.com/ and enter your device __API key__ in order to connect it to the device.\n",
        "4. Write a micropython code script that gets the temperature and humidity from the ENV-III sensor and displays it on the device's screen. Use labels with proper names to indicate which value on the screen belongs to temperature and which one belongs to humidity. The temperature and humidity values should be updated every 1 minute.\n",
        "  - Try to round the temperature and humidity values. You can do that by modifying the micropythin code in UIFlow.\n",
        "5. Program the Core2 device with your code and check the result.\n",
        "\n",
        "If everything goes in order, you should be able to see a result similar to the image below:\n",
        "\n",
        "<img src=\"https://drive.usercontent.google.com/download?id=13YAw1-6T7GeZvnXLXCLpmTNUfhiiU5GK\" width=\"300\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULiu0rfM_l1J"
      },
      "source": [
        "-------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmAms42m_l1J"
      },
      "source": [
        "# 3. Creating a BigQuery database with the proper schema\n",
        "In this part we will create a BigQuery database. First we have to define the schema of this database, i.e., what will be the columns of this database and what will be the data type of each column. Then we will see how we can add a new row to a database using a SQL query."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NXPah68_l1J"
      },
      "source": [
        "## 3.1 Defining a new BigQuery database\n",
        "First, we need to define a new BigQuery database. This database will be later used to insert the historical weather data in it. Follow the steps below to create this database.\n",
        "\n",
        "1. In your Google Cloud console, go to the BigQuery interface.\n",
        "2. From the menu on the left select BigQuery Studio.\n",
        "\n",
        "<img src=\"https://drive.usercontent.google.com/download?id=1EU4SxFTcuZRtevbF7N7VX9619EwrsiNi\" width=\"300\">\n",
        "\n",
        "3. From the pannel on the left, click on the three dots next to your project name and select create dataset. This will create a new dataset in BigQuery.\n",
        "\n",
        "<img src=\"https://drive.usercontent.google.com/download?id=1OGCVf1pbpFYEkN76XEC9Kj7_RRKgW3y2\" width=\"300\">\n",
        "\n",
        "4. Assign a proper name to the dataset and select the region for the dataset.\n",
        "\n",
        "<img src=\"https://drive.usercontent.google.com/download?id=1dYmV2NfikHufCPOUaZEYmKPVcPzXBH_8\" width=\"300\">\n",
        "\n",
        "5. Create a new table in the new dataset. You can call it: **weather-records**\n",
        "\n",
        "<img src=\"https://drive.usercontent.google.com/download?id=19kaG5orQd_JDjg_gPe4VW3LtPrBNKQUE\" width=\"300\">\n",
        "\n",
        "6. We will create this table from an \"Empty Table\". Also we need to define the schema of this table. Define the schema according to the following image.\n",
        "\n",
        "<img src=\"https://drive.usercontent.google.com/download?id=1GcuRVOHXjWMMbKFCjwZcfrOWs4eSIeJo\" width=\"600\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISaOacs3_l1K"
      },
      "source": [
        "## 3.2 Test the BigQuery database we just created (authentification Google Colab)\n",
        "Now let's query the database we just created. The result of the query is expected to be an empty table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XKazZvFZ_l1K",
        "outputId": "34c85025-176e-4c9b-9a98-f5205a632d14",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authenticated\n"
          ]
        }
      ],
      "source": [
        "# import the required packages in this walkthrough\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests\n",
        "import time\n",
        "from datetime import datetime\n",
        "import os\n",
        "import pandas as pd\n",
        "import hashlib\n",
        "from google.cloud import bigquery\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "print(\"Authenticated\")\n",
        "# If you want to use your local jupyter notebook:\n",
        "#Â os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"path-to-service-account-key-json\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "smi0ghfz_l1K"
      },
      "outputs": [],
      "source": [
        "# Define the BigQuery client\n",
        "client = bigquery.Client(project=\"YOUR-PROJECT-ID\") # PROJECT_ID"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YG0GSGKA_l1L"
      },
      "outputs": [],
      "source": [
        "\n",
        "q = \"\"\"\n",
        "SELECT * FROM `PROJECT_ID.DATABAE_ID.weather-records`\n",
        "LIMIT 10\n",
        "\"\"\"\n",
        "\n",
        "query_job = client.query(q)\n",
        "df = query_job.to_dataframe()\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zud67viy_l1L"
      },
      "source": [
        "## 3.3 Insert new rows in the BigQuery table\n",
        "For this application, we need to insert new rows in the BigQuery table in order to be able to keep track of the historical data. To do this we can use the SQL `INSERT` statement. See the documentation to know more about the syntax of this statement: https://cloud.google.com/bigquery/docs/reference/standard-sql/dml-syntax#insert_statement\n",
        "\n",
        "Note that if you do not specify any values for some of the columns, those columns will get a NULL value. Follow the following examples to better understand how does the `INSERT` statement works."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EcW59R1c_l1L"
      },
      "outputs": [],
      "source": [
        "# Insert some random values!\n",
        "q = f\"\"\"\n",
        "INSERT INTO `PROJECT_ID.DATABAE_ID.weather-records`\n",
        "(date, time, indoor_temp, indoor_humidity)\n",
        "VALUES('2024-03-15', '16:02:23', 23, 65)\n",
        "\"\"\"\n",
        "\n",
        "query_job = client.query(q)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FVI9qe0A_l1L"
      },
      "outputs": [],
      "source": [
        "# Now we can query the database again and see the new row added to it!\n",
        "# PROJECT_ID.DATABAE_ID.weather-records\n",
        "q = \"\"\"\n",
        "SELECT * FROM `PROJECT_ID.DATABAE_ID.weather-records`\n",
        "LIMIT 10\n",
        "\"\"\"\n",
        "\n",
        "query_job = client.query(q)\n",
        "df = query_job.to_dataframe()\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmyH05h8_l1L"
      },
      "source": [
        "-------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRs6k-es_l1L"
      },
      "source": [
        "# 4. Creating a web service that receives data from the IoT device\n",
        "Because of the limitations of the micropython, we are not able to install Google Cloud packages on the device and therefore we are not able to directly query the BigQuery table from the device. Therefore, we need to create a web service accesible via the Internet, so that we can send the data from the device to that web service. The job of the web service is to receive the data from the M5stack device and insert it in the BigQuery table.\n",
        "\n",
        "The script `main.py` in the folder `web_app` will create a simple Flask application that can recieve data from the IoT device and insert it into your BigQuery database. pay attention to the following remarks about this flask app:\n",
        "\n",
        "- A flask app in general can have multiple endpoint. In this part, we want to use the `/send-to-bigquery` endpoint. This endpoint will accept a post request from the IoT device that contains the indoor temperature values inside a json file. Then it builds a SQL query based on these values and sends this query to the BigQuery database. Please take a moment and look carefully how the SQL query is being made.\n",
        "- It is important to make sure that only you, as the owner of the database, can call this endpoint and insert new rows inside the database! To do so, we need to make the calls to this endpoint __authenticated__. One way to do that is to set up a password which will be checked on the flask server. To avoid sending the password from the IoT device in plain text, we need to hash this password first and send it to the flask server. In the flask server, the correct hash string is already stored and each time a post request is made the received hash string (from the IoT device) will be checked against the stored hash string. In the `m5stack.py` script, see how we have set-up a password and converted it to a hash string. In the `main.py` script (flask app), see how the correctness of the hash string is checked for each post request. To know more about hash functions, check the [wikipedia page](https://en.wikipedia.org/wiki/Hash_function).\n",
        "- In the `m5stack.py` script select a password for yourself (the `passwd` variable).\n",
        "- In the `m5stack.py` script, observe that we send data to the flask app every 5 minutes.\n",
        "- You need to store the hash of your password in the flask server. You can use the code cell below to hash your password. Copy the result to the `main.py` file (`YOUR_HASH_PASSWD` variable)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8yHkCY2j_l1L"
      },
      "outputs": [],
      "source": [
        "h = hashlib.sha256(b\"<YOUR_PASSWORD>\")\n",
        "h.hexdigest()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXmTZoYc_l1M"
      },
      "source": [
        "To test the endpoint locally on your computer, you can dowonload the `main.py` file and run it on your computer.\n",
        "\n",
        "In your terminal run `python main.py`.\n",
        "\n",
        "You can use the following cell to test your endpoint locally. __Note that the following cell will not work in colab since the service is now running only locally on your computer.__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5LPTX5Rt_l1M"
      },
      "outputs": [],
      "source": [
        "data = {\n",
        "    \"passwd\": \"YOUR-PASSWORD-HASH\",\n",
        "    \"values\": {\n",
        "        \"date\": \"<some_random_date>\", # example of the correct format: '2024-02-22'\n",
        "        \"time\": \"<some_random_time>\", # example of the correct format: '16:30:00'\n",
        "        \"indoor_temp\": 23, # random values for the indoor temperature and humidity\n",
        "        \"indoor_humidity\": 67\n",
        "    }\n",
        "}\n",
        "\n",
        "requests.post(\"http://0.0.0.0:8080/send-to-bigquery\", json=data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYBpK0r__l1M"
      },
      "source": [
        "If you have replaced the place holders with the correct string/values, then after running the above cell you should see the new row being added to your db."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EPvhDbgG_l1M"
      },
      "outputs": [],
      "source": [
        "\n",
        "q = \"\"\"\n",
        "SELECT * FROM `PROJECT_ID.DATABAE_ID.weather-records`\n",
        "LIMIT 10\n",
        "\"\"\"\n",
        "\n",
        "query_job = client.query(q)\n",
        "df = query_job.to_dataframe()\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZ8DG104_l1M"
      },
      "source": [
        "-------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQbopvgS_l1M"
      },
      "source": [
        "# 5. Deploying the Flask app in Google Cloud\n",
        "\n",
        "To deploy the Flask app in the Gcloud Cloud Run, you have to follow the following steps:\n",
        "1. Download the following files from the course repository and push them to your private repository.\n",
        "    - `main.py`\n",
        "    - `requirements.txt`\n",
        "    - `Dockerfile`\n",
        "2. Navigate to Cloud Run in your Google Cloud console and open a cloud shell terminal.\n",
        "3. In the terminal navigate to the directory corresponding to your git repository and do `git pull`\n",
        "4. Follow the instructions in lab 1 to build the docker image and push it to the container registry.\n",
        "5. Follow the instrucitons in lab 1 to deploy the created image in the container registry to Cloud Run.\n",
        "\n",
        "After completing the above steps successfully, you would get a URL for Flask web service. Try to insert some artificial data to the BigQuery db using the URL. You can use the code below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y27i4r42_l1M"
      },
      "outputs": [],
      "source": [
        "data = {\n",
        "    \"passwd\": \"YOUR-PASSWORD-HASH\",\n",
        "    \"values\": {\n",
        "        \"date\": \"<some_random_date>\", # example of the correct format: '2024-02-22'\n",
        "        \"time\": \"<some_random_time>\", # example of the correct format: '16:30:00'\n",
        "        \"indoor_temp\": 23, # random values for the indoor temperature and humidity\n",
        "        \"indoor_humidity\": 67\n",
        "    }\n",
        "}\n",
        "\n",
        "requests.post(\"<URL_FROM_CLOUDRUN>/send-to-bigquery\", json=data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_j7V4Wu_l1N"
      },
      "source": [
        "Check if the data has been inserted correctly to the db."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5JlWY1RA_l1N"
      },
      "outputs": [],
      "source": [
        "# PROJECT_ID.DATABAE_ID.weather-records\n",
        "q = \"\"\"\n",
        "SELECT * FROM `PROJECT_ID.DATABAE_ID.weather-records`\n",
        "LIMIT 10\n",
        "\"\"\"\n",
        "\n",
        "query_job = client.query(q)\n",
        "df = query_job.to_dataframe()\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZM6MKPM_l1N"
      },
      "source": [
        "-------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jiYoiraC_l1N"
      },
      "source": [
        "# 6. Updating the `m5stack.py` with the URL of the deployed web service\n",
        "\n",
        "Finally, you have to update the `m5stack.py` file with the URL of the web service you just deployed. After doing so, program the Core2 device with the new script. In the first iteration of the loop, the values of the ENV-III measurements will be sent to the server. So you sould be able to see the values added to the db almost immediately (You can check it by running a query!). After that, you should be able to see new values added to the server every 5 minutes!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XEtTI9U_l1N"
      },
      "source": [
        "-------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I65xantO_l1N"
      },
      "source": [
        "# 7. Your Turn\n",
        "\n",
        "1. Right now we are only inserting the measurements of the ENV-III sensor, temperature and humidity, to the db every 5 minutes. However, it is impossible to keep track of the historical data without keeping track of the actual time they were recorded. Therefore, we need to also send the time of the measurements from the Core2 device to the server. Try to do that! (Hint: check the `npttime` package: https://mpython.readthedocs.io/en/v2.2.1/library/micropython/ntptime.html)\n",
        "\n",
        "2. In the Flask server, augment the `/send-to-bigquery` endpoint such that for each post request it gets the weather information from the openweather api and insert the corresponding values in the `outdoor_weather`, `outdoor_humidity`, and `outdoor_weather` columns of the db. For the `outdoor_weather` column, use the value corresponding to the key `description` from the json file you get from the openweather api.\n",
        "\n",
        "3. Create a new endpoint `/get_outdoor_weather` in the Flask app that accepts post requests and sends back the outdoor humidity and temperature values it gets from the lastest entry in the db. For security reasons, to make sure that only you can see the records of your db, check the password in this method as well. Try to use this endpoint in the Core2 device so that you can show the outdoor weather info on the device.\n",
        "    3.1. __bonus__: Can you also show the current date and time on the device?\n",
        "    \n",
        "\n",
        "After doing the 2nd and 3rd exercises, you can expect ot have this information on your Core2 device:\n",
        "\n",
        "<img src=\"https://drive.usercontent.google.com/download?id=1fFtimdTCoP0GsL561hISafFbFe9fFeaP\" width=\"500\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YBv7snTe_l1N"
      },
      "outputs": [],
      "source": [
        "# Help to call the openweather api\n",
        "\n",
        "API_key = \"YOUR_API_KEY\"\n",
        "\n",
        "city = \"Lausanne\"\n",
        "\n",
        "url = f'http://api.openweathermap.org/data/2.5/weather?q={city}&appid={API_key}&units=metric'\n",
        "\n",
        "response = requests.get(url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7PBSavhH_l1O",
        "outputId": "d73afd76-f685-408d-a168-68cf694fa7cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "temp: 9, humidity: 77, weather: overcast clouds\n"
          ]
        }
      ],
      "source": [
        "temp = round(response.json()['main']['temp'])\n",
        "humidity = round(response.json()['main']['humidity'])\n",
        "weather = response.json()['weather'][0]['description']\n",
        "\n",
        "print(f\"temp: {temp}, humidity: {humidity}, weather: {weather}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5ETytao6D-6v"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:caa24]",
      "language": "python",
      "name": "conda-env-caa24-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}